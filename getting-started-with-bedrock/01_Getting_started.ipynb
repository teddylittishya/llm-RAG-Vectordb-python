{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "331d43e6-031d-4dc3-ba24-eeb453a14055",
   "metadata": {},
   "source": [
    "# Gettings started with Amazon `Bedrock`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d55a7d-204a-4738-904a-2da5a695fb82",
   "metadata": {},
   "source": [
    "![](images/bedrock_models.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab536f45-a505-4341-83d4-a2cf64039b88",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Create a `bedrock` client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdc42da1-a040-4de2-bf1e-ed08ef3ad5bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3\n",
    "import base64\n",
    "\n",
    "\n",
    "\n",
    "#Create the connection to Bedrock\n",
    "bedrock = boto3.client(\n",
    "    service_name='bedrock',\n",
    "    region_name='us-west-2', \n",
    ")\n",
    "\n",
    "bedrock_runtime = boto3.client(\n",
    "    service_name='bedrock-runtime',\n",
    "    region_name='us-west-2', \n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b918e6-78a1-4426-813a-0608892089bb",
   "metadata": {
    "tags": []
   },
   "source": [
    "### List of all available models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d421313-4275-4ab2-824c-ebd543345574",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['amazon.titan-tg1-large',\n",
       " 'amazon.titan-embed-g1-text-02',\n",
       " 'amazon.titan-text-lite-v1:0:4k',\n",
       " 'amazon.titan-text-lite-v1',\n",
       " 'amazon.titan-text-express-v1:0:8k',\n",
       " 'amazon.titan-text-express-v1',\n",
       " 'amazon.titan-embed-text-v1:2:8k',\n",
       " 'amazon.titan-embed-text-v1',\n",
       " 'amazon.titan-embed-image-v1:0',\n",
       " 'amazon.titan-embed-image-v1',\n",
       " 'amazon.titan-image-generator-v1:0',\n",
       " 'amazon.titan-image-generator-v1',\n",
       " 'stability.stable-diffusion-xl',\n",
       " 'stability.stable-diffusion-xl-v0',\n",
       " 'stability.stable-diffusion-xl-v1:0',\n",
       " 'stability.stable-diffusion-xl-v1',\n",
       " 'ai21.j2-grande-instruct',\n",
       " 'ai21.j2-jumbo-instruct',\n",
       " 'ai21.j2-mid',\n",
       " 'ai21.j2-mid-v1',\n",
       " 'ai21.j2-ultra',\n",
       " 'ai21.j2-ultra-v1',\n",
       " 'anthropic.claude-instant-v1:2:100k',\n",
       " 'anthropic.claude-instant-v1',\n",
       " 'anthropic.claude-v2:0:18k',\n",
       " 'anthropic.claude-v2:0:100k',\n",
       " 'anthropic.claude-v2:1:18k',\n",
       " 'anthropic.claude-v2:1:200k',\n",
       " 'anthropic.claude-v2:1',\n",
       " 'anthropic.claude-v2',\n",
       " 'anthropic.claude-3-sonnet-20240229-v1:0',\n",
       " 'cohere.command-text-v14:7:4k',\n",
       " 'cohere.command-text-v14',\n",
       " 'cohere.command-light-text-v14:7:4k',\n",
       " 'cohere.command-light-text-v14',\n",
       " 'cohere.embed-english-v3',\n",
       " 'cohere.embed-multilingual-v3',\n",
       " 'meta.llama2-13b-chat-v1:0:4k',\n",
       " 'meta.llama2-13b-chat-v1',\n",
       " 'meta.llama2-70b-chat-v1:0:4k',\n",
       " 'meta.llama2-70b-chat-v1',\n",
       " 'meta.llama2-13b-v1:0:4k',\n",
       " 'meta.llama2-13b-v1',\n",
       " 'meta.llama2-70b-v1:0:4k',\n",
       " 'meta.llama2-70b-v1',\n",
       " 'mistral.mistral-7b-instruct-v0:2',\n",
       " 'mistral.mixtral-8x7b-instruct-v0:1']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List all foundation models\n",
    "all_llms = [ model['modelId'] for model in bedrock.list_foundation_models()['modelSummaries']]\n",
    "all_llms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7624768d-a79c-417e-aec5-272e95df6bf3",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Define prompt and model parameters "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4424ed56-7725-4b51-b027-ee53b2de1b48",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### With `Amazon Titan`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a9ba82-62d6-49bd-ac1e-967d5bc59d97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_data = \"\"\"Write me a poem about apples\"\"\"\n",
    "\n",
    "text_gen_config = {\n",
    "                    \"maxTokenCount\": 512,\n",
    "                    \"stopSequences\": [], \n",
    "                    \"temperature\": 0,\n",
    "                    \"topP\": 0.9\n",
    "                }\n",
    "\n",
    "body = json.dumps({\n",
    "                        \"inputText\": prompt_data,\n",
    "                        \"textGenerationConfig\": text_gen_config  \n",
    "                    })\n",
    "\n",
    "model_id = 'amazon.titan-tg1-large'\n",
    "accept = 'application/json' \n",
    "content_type = 'application/json'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc650c9-a75c-4ed4-ae0a-e3e0a5e38914",
   "metadata": {},
   "source": [
    "#### Invoke model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3702c51b-a622-4635-aeb7-e3309013ef29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = bedrock_runtime.invoke_model(\n",
    "                                            body=body, \n",
    "                                            modelId=model_id, \n",
    "                                            accept=accept, \n",
    "                                            contentType=content_type\n",
    "                                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9e7285-e061-4886-934f-904da5d43fa7",
   "metadata": {},
   "source": [
    "#### Print response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06be453a-62d5-400e-aca1-f3b1beb0dd1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response_body = json.loads(response['body'].read())\n",
    "print(response_body['results'][0]['outputText'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfac6718-0a38-40c1-a31d-0bc6d8301e22",
   "metadata": {
    "tags": []
   },
   "source": [
    "### With `Anthropic (Claude v3 (Sonnet))`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d357de4b-8c0d-4317-b14e-b099adbe722c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_data = \"\"\"What is L in LLM means\"\"\"\n",
    "\n",
    "body = {\n",
    "            \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "            \"max_tokens\": 1024,\n",
    "            \"messages\": [\n",
    "                 {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\n",
    "                            \"type\": \"text\",\n",
    "                            \"text\": prompt_data\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "            ],\n",
    "        }\n",
    "\n",
    "body = json.dumps(body) # Encode body as JSON string\n",
    "\n",
    "model_id = \"anthropic.claude-3-sonnet-20240229-v1:0\"\n",
    "accept = 'application/json'\n",
    "contentType = 'application/json'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b8cb2f-0478-4697-86d0-590fbf8be22d",
   "metadata": {},
   "source": [
    "#### Invoke model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c204dee-e262-4c40-becf-8af9255f6145",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = bedrock_runtime.invoke_model(body=body,\n",
    "                                        modelId=model_id, \n",
    "                                        accept=accept, \n",
    "                                        contentType=contentType)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76de6d86-bff5-4a73-a2ff-c7ec38c49d81",
   "metadata": {},
   "source": [
    "#### Print response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afe2e98a-515f-4896-89fe-d96f1e4b00c2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the context of LLM, the 'L' stands for 'Large' Language Model.\n",
      "\n",
      "An LLM (Large Language Model) refers to a type of advanced language model that has been trained on a massive amount of text data from the internet and other sources. These models are called \"large\" because they typically have billions or even trillions of parameters, making them significantly larger and more complex than earlier language models.\n",
      "\n",
      "Some key characteristics of LLMs:\n",
      "\n",
      "1) Massive training data: LLMs are trained on vast corpora of text from diverse sources like websites, books, articles etc. This allows them to learn patterns and relationships across a wide range of topics.\n",
      "\n",
      "2) Self-attention mechanism: They employ transformer architectures with self-attention mechanisms that can capture long-range dependencies better than RNNs.\n",
      "\n",
      "3) Multi-task capability: With sufficient training data, LLMs can perform well on a variety of natural language tasks like text generation, question answering, summarization etc.\n",
      "\n",
      "4) Few/Zero-shot learning: Their broad knowledge allows LLMs to generalize and perform reasonably well on unseen tasks with few examples or prompts.\n",
      "\n",
      "Some well-known examples of LLMs are GPT-3 by OpenAI, PaLM by Google, and models like myself trained by Anthropic. The \"large\" size gives these models increased versatility and capability compared to smaller language models.\n"
     ]
    }
   ],
   "source": [
    "response_body = json.loads(response.get(\"body\").read())\n",
    "for output in response_body.get(\"content\", []):\n",
    "    print(output[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f983c62-5db4-4939-99cd-01ed5cf50ece",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### With `Mistral (mixtral-8x7b)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9fd10c-b83f-45c4-9e1a-9b55e1736354",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_data = \"\"\"<s>[INST]Craft a Python function to convert Celsius to Fahrenheit. If water boils at 100°C, what's that in Fahrenheit?[/INST]\"\"\"\n",
    "\n",
    "body = json.dumps({ \n",
    "    'prompt': prompt_data,\n",
    "    'max_tokens': 200,\n",
    "    'top_p': 0.9,\n",
    "    'temperature': 0.2,\n",
    "})\n",
    "\n",
    "\n",
    "modelId = 'mistral.mixtral-8x7b-instruct-v0:1'\n",
    "accept = 'application/json'\n",
    "contentType = 'application/json'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a83e979-9d72-4ab7-9acb-3afc89687213",
   "metadata": {},
   "source": [
    "#### Invoke model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a285cc8b-b9df-4339-8b69-8e9594a8e9af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = bedrock_runtime.invoke_model(body=body.encode('utf-8'), # Encode to bytes\n",
    "                                        modelId=modelId, \n",
    "                                        accept=accept, \n",
    "                                        contentType=contentType)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15918b5d-1068-4d93-9309-c1d3f2e903b6",
   "metadata": {},
   "source": [
    "#### Print response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e49eef-0d1b-43c2-a6a6-5a8aca398db0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response_body = json.loads(response.get('body').read().decode('utf-8'))\n",
    "print(response_body.get('outputs')[0].get('text'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5656ce38-e3dd-492f-b035-8a708cbe34b3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Syntax Multi-Modal models from `Anthropic Claude v3 Models`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79dcda90-954d-4c0c-92a2-cb2479f0adb1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"images/cat.png\", \"rb\") as image_file:\n",
    "    encoded_string = base64.b64encode(image_file.read())\n",
    "    base64_string = encoded_string.decode('utf-8')\n",
    "\n",
    "payload = {\n",
    "    \"modelId\": \"anthropic.claude-3-sonnet-20240229-v1:0\",\n",
    "    \"contentType\": \"application/json\",\n",
    "    \"accept\": \"application/json\",\n",
    "    \"body\": {\n",
    "        \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "        \"max_tokens\": 1000,\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"image\",\n",
    "                        \"source\": {\n",
    "                            \"type\": \"base64\",\n",
    "                            \"media_type\": \"image/png\",\n",
    "                            \"data\": base64_string\n",
    "                        }\n",
    "                    },\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": \"Write me a detailed description of this photo.\"\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Convert the payload to bytes\n",
    "body_bytes = json.dumps(payload['body']).encode('utf-8')\n",
    "\n",
    "# Invoke the model\n",
    "model_id = \"anthropic.claude-3-sonnet-20240229-v1:0\"\n",
    "accept = 'application/json'\n",
    "contentType = 'application/json'\n",
    "\n",
    "response = bedrock_runtime.invoke_model(body=body_bytes,\n",
    "                                        modelId=model_id, \n",
    "                                        accept=accept, \n",
    "                                        contentType=contentType)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3482f6-bfa5-4006-867e-e5a35a089e8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response_body = json.loads(response.get('body').read().decode('utf-8'))\n",
    "print(response_body.get('content')[0].get('text'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f57584-eca6-4602-a6a6-ab39528d13c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
